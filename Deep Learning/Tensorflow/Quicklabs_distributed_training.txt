#Start by setting the default compute zone and a couple of environment variables:

gcloud config set compute/zone us-central1-f

PROJECT_ID=$(gcloud config get-value project)
CLUSTER_NAME=cluster-1


#Now, create the cluster. The below command may take a few minutes to complete.

gcloud beta container clusters create $CLUSTER_NAME \
  --project=$PROJECT_ID \
  --cluster-version=latest \
  --machine-type=n1-standard-4 \
  --scopes compute-rw,gke-default,storage-rw \
  --num-nodes=3

#After the cluster has started, configure access credentials so you can interact with the cluster using kubectl.
gcloud container clusters get-credentials $CLUSTER_NAME


#TFJob is a component of Kubeflow.
#It is usually deployed as part of a full Kubeflow installation but can also be used in a standalone configuration. 
#In this lab, you will install TFJob as a standalone component.

#TFJob consists of two parts: a Kubernetes custom resource and an operator implementing the job management logic. 
#Kubernetes manifests for both the custom resource definition and the operator are managed in Kubeflow GitHub repository.

#Instead of cloning the whole repository you will retrieve the TFJob manifests only using an OSS tool - kpt - that is pre-installed in Cloud Shell.


#Get the manifests for TFJob from v1.1.0 of Kubeflow.

cd
SRC_REPO=https://github.com/kubeflow/manifests
kpt pkg get $SRC_REPO/tf-training@v1.1.0 tf-training
kubectl create namespace kubeflow

#Create a Kubernetes namespace to host the TFJob operator.
kubectl create namespace kubeflow

#Install the TFJob custom resource.
kubectl apply  --kustomize tf-training/tf-job-crds/base

#Install the TFJob operator.
kubectl apply  --kustomize tf-training/tf-job-operator/base

#Verify the installation
kubectl get deployments -n kubeflow

#Notice that the TFJob operator is running as a Kubernetes Deployment in the kubeflow namespace.

#As described in the lab overview, the distributed training script stores training checkpoints and the trained model in the SavedModel format to the storage location passed as one of the script's arguments.
#You will use a Cloud Storage bucket as a shared persistent storage.

#Since storage buckets are a global resource in Google Cloud you have to use a unique bucket name.
# For the purpose of this lab, you can use your project id as a name prefix.

export TFJOB_BUCKET=${PROJECT_ID}-bucket
gsutil mb gs://${TFJOB_BUCKET}

#Your distributed training environment is ready and you can now prepare and submit distributed training jobs.

#The TensorFlow training code and the TFJob manifest template used in the lab can be retrieved from GitHub.

cd
SRC_REPO=https://github.com/GoogleCloudPlatform/mlops-on-gcp
kpt pkg get $SRC_REPO/workshops/mlep-qwiklabs/distributed-training-gke lab-files
cd lab-files

#The training module is in the mnist folder. 
#The model.py file contains a function to create a simple convolutional network. 
#The main.py file contains data preprocessing routines and a distributed training loop. Review the files.
# Notice how you can use a tf.distribute.experimental.MultiWorkerMirrorStrategy() object to retrieve information about the topology of the distributed cluster running a job.


#You can also see how to configure automatic checkpointing using tf.keras.callbacks.experimental.BackupAndRestore()

#You can control the training loop by passing command line arguments to the main.py script. We will use it when configuring a TFJob manifest.

#Packaging training code in a docker image
#Before submitting the job, the training code must be packaged in a docker image and pushed into your project's Container Registry.
#You can find the Dockerfile that creates the image in the lab-files folder. 
#You do not need to modify the Dockerfile.

#To build the image and push it to the registry execute the below commands.

IMAGE_NAME=mnist-train

docker build -t gcr.io/${PROJECT_ID}/${IMAGE_NAME} .
docker push gcr.io/${PROJECT_ID}/${IMAGE_NAME}

#As noted in the lab overview, you have a lot of flexibility in defining the job's process topology and allocating hardware resources. 
#Please refer to the TFJob guide for more information.

The key field in the TFJob manifest is tfReplicaSpecs, which defines the number and the types of replicas (pods) created by a job. 
#In our case, the job will start 3 workers using the container image defined in the image field and command line arguments defined in the args field.
#Before submitting a job, you need to update the image and args fields with the values reflecting your environment.
#Use your preferred command line editor or Cloud Shell Editor to update the image field with a full name of the image you created and pushed to your Container Registry in the previous step. 
#You can retrieve the image name using the following command.

gcloud container images list

#You can now submit the job using kubectl.
kubectl apply -f tfjob.yaml

#During execution, TFJob will emit events to indicate the status of the job,
 #including creation/deletion of pods and services.

#You can retrieve the recent events and other information about the job by executing the following command.

JOB_NAME=multi-worker
kubectl describe tfjob $JOB_NAME

#To remove the job and the associated pods:
kubectl delete tfjob $JOB_NAME
